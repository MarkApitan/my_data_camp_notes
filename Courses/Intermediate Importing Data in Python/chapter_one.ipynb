{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Importing Data in Python\n",
    "\n",
    "## Importing flat files from the web\n",
    "\n",
    "### The urllib package\n",
    "- provides interface for fetching data across the web\n",
    "- urlopen() -  accepts URLs instead of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('winequality-white.csv', <http.client.HTTPMessage at 0x1d1f51f3d10>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve \n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "urlretrieve(url, 'winequality-white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve \n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xls\n",
    "xls = pd.read_excel(url, sheet_name = None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xls.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xls['1700'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP requests to import files from the web\n",
    "\n",
    "### URL\n",
    "- Uniform/Universal Resource Locator\n",
    "- References to web resources\n",
    "- Focus: web addresses\n",
    "- Consists of:\n",
    "    - Protocol identifier - http:\n",
    "    - Resource name - datacamp.com\n",
    "- These specify web addresses uniquely\n",
    "\n",
    "### HTTP\n",
    "- HyperText Transfer Protocol\n",
    "- Foundation of data communication for the web\n",
    "- HTTPS - more secure form of HTTP\n",
    "    - GET request\n",
    "    - urlretrieve() performs a GET request\n",
    "- HTML - HyperText Markup Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "url  = \"http://www.wikipedia.org/\"\n",
    "request = Request(url)\n",
    "response = urlopen(request)\n",
    "html = response.read()\n",
    "response.close()\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET request using request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://www.wikipedia.org/\"\n",
    "r = requests.get(url)\n",
    "text = r.text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Web in Python\n",
    "\n",
    "### BeautifulSoup\n",
    "- Parse and extract structured data from HTML\n",
    "- Make tag soup beautiful and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n",
      "\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <style>\n",
      "   #tidelift { }\n",
      "\n",
      "#tidelift a {\n",
      " border: 1px solid #666666;\n",
      " margin-left: auto;\n",
      " padding: 10px;\n",
      " text-decoration: none;\n",
      "}\n",
      "\n",
      "#tidelift .cta {\n",
      " background: url(\"tidelift.svg\") no-repeat;\n",
      " padding-left: 30px;\n",
      "}\n",
      "  </style>\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   [\n",
      "   <a href=\"#Download\">\n",
      "    Download\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"bs4/doc/\">\n",
      "    Documentation\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"#HallOfFame\">\n",
      "    Hall of Fame\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"enterprise.html\">\n",
      "    For enterprise\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "    Source\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://git.launchpad.net/beautifulsoup/tree/CHANGELOG\">\n",
      "    Changelog\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "    Discussion group\n",
      "   </a>\n",
      "   |\n",
      "   <a href=\"zine/\">\n",
      "    Zine\n",
      "   </a>\n",
      "   ]\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "  </div>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "   <ol>\n",
      "    <li>\n",
      "     Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "     <li>\n",
      "      Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "      <li>\n",
      "       Beautiful Soup sits on top of popular Python parsers like\n",
      "       <a href=\"http://lxml.de/\">\n",
      "        lxml\n",
      "       </a>\n",
      "       and\n",
      "       <a href=\"http://code.google.com/p/html5lib/\">\n",
      "        html5lib\n",
      "       </a>\n",
      "       , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "      </li>\n",
      "     </li>\n",
      "    </li>\n",
      "   </ol>\n",
      "   <p>\n",
      "    Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "    <tt>\n",
      "     externalLink\n",
      "    </tt>\n",
      "    \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "    <p>\n",
      "     Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "     <p>\n",
      "      Interested?\n",
      "      <a href=\"bs4/doc/\">\n",
      "       Read more.\n",
      "      </a>\n",
      "      <h3>\n",
      "       Getting and giving support\n",
      "      </h3>\n",
      "      <div align=\"center\" id=\"tidelift\">\n",
      "       <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
      "        <span class=\"cta\">\n",
      "         Beautiful Soup for enterprise available via Tidelift\n",
      "        </span>\n",
      "       </a>\n",
      "      </div>\n",
      "      <p>\n",
      "       If you have questions, send them to\n",
      "       <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "        the discussion\n",
      "group\n",
      "       </a>\n",
      "       . If you find a bug,\n",
      "       <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "        file it on Launchpad\n",
      "       </a>\n",
      "       . If it's a security vulnerability, report it confidentially through\n",
      "       <a href=\"https://tidelift.com/security\">\n",
      "        Tidelift\n",
      "       </a>\n",
      "       .\n",
      "      </p>\n",
      "      <p>\n",
      "       If you use Beautiful Soup as part of your work, please consider a\n",
      "       <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "        Tidelift subscription\n",
      "       </a>\n",
      "       . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "       <p>\n",
      "        If Beautiful Soup is useful to you on a personal level, you might like to read\n",
      "        <a href=\"zine/\">\n",
      "         <i>\n",
      "          Tool Safety\n",
      "         </i>\n",
      "        </a>\n",
      "        , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "       </p>\n",
      "       <a name=\"Download\">\n",
      "        <h2>\n",
      "         Download Beautiful Soup\n",
      "        </h2>\n",
      "       </a>\n",
      "       <p>\n",
      "        The current release is\n",
      "        <a href=\"bs4/download/\">\n",
      "         Beautiful Soup\n",
      "4.12.3\n",
      "        </a>\n",
      "        (January 17, 2024). You can install Beautiful Soup 4 with\n",
      "        <code>\n",
      "         pip install beautifulsoup4\n",
      "        </code>\n",
      "        .\n",
      "        <p>\n",
      "         In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "         <code>\n",
      "          python3-bs4\n",
      "         </code>\n",
      "         package. In Fedora it's\n",
      "available as the\n",
      "         <code>\n",
      "          python3-beautifulsoup4\n",
      "         </code>\n",
      "         package.\n",
      "         <p>\n",
      "          Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "          <code>\n",
      "           bs4/\n",
      "          </code>\n",
      "          directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately.\n",
      "          <p>\n",
      "           Beautiful Soup 4 is supported on Python versions 3.6 and\n",
      "greater. Support for Python 2 was discontinued on January 1, 2021—one\n",
      "year after the Python 2 sunsetting date.\n",
      "           <h3>\n",
      "            Beautiful Soup 3\n",
      "           </h3>\n",
      "           <p>\n",
      "            Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and was\n",
      "discontinued or January 1, 2021—one year after the Python 2\n",
      "sunsetting date. If you have any active projects using Beautiful Soup\n",
      "3, you should migrate to Beautiful Soup 4 as part of your Python 3\n",
      "conversion.\n",
      "            <p>\n",
      "             <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "              Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "             </a>\n",
      "             <p>\n",
      "              The current and hopefully final release of Beautiful Soup 3 is\n",
      "              <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">\n",
      "               3.2.2\n",
      "              </a>\n",
      "              (October 5,\n",
      "2019). It's the\n",
      "              <code>\n",
      "               BeautifulSoup\n",
      "              </code>\n",
      "              package on pip. It's also\n",
      "available as\n",
      "              <code>\n",
      "               python-beautifulsoup\n",
      "              </code>\n",
      "              in Debian and Ubuntu,\n",
      "and as\n",
      "              <code>\n",
      "               python-BeautifulSoup\n",
      "              </code>\n",
      "              in Fedora.\n",
      "              <p>\n",
      "               Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "               <p>\n",
      "                Beautiful Soup 3, like Beautiful Soup 4, is\n",
      "                <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "                 supported through Tidelift\n",
      "                </a>\n",
      "                .\n",
      "               </p>\n",
      "               <a name=\"HallOfFame\">\n",
      "                <h2>\n",
      "                 Hall of Fame\n",
      "                </h2>\n",
      "               </a>\n",
      "               <p>\n",
      "                Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "                <ul>\n",
      "                 <li>\n",
      "                  <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "                   \"Movable\n",
      " Type\"\n",
      "                  </a>\n",
      "                  , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "                  <li>\n",
      "                   Jiabao Lin's\n",
      "                   <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">\n",
      "                    DXY-COVID-19-Crawler\n",
      "                   </a>\n",
      "                   uses Beautiful Soup to scrape a Chinese medical site for information\n",
      "about COVID-19, making it easier for researchers to track the spread\n",
      "of the virus. (Source:\n",
      "                   <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\n",
      "                    \"How open source software is fighting COVID-19\"\n",
      "                   </a>\n",
      "                   )\n",
      "                   <li>\n",
      "                    Reddit uses Beautiful Soup to\n",
      "                    <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "                     parse\n",
      "a page that's been linked to and find a representative image\n",
      "                    </a>\n",
      "                    .\n",
      "                    <li>\n",
      "                     Alexander Harrowell uses Beautiful Soup to\n",
      "                     <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "                      track the business\n",
      " activities\n",
      "                     </a>\n",
      "                     of an arms merchant.\n",
      "                     <li>\n",
      "                      The developers of Python itself used Beautiful Soup to\n",
      "                      <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "                       migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "                      </a>\n",
      "                      .\n",
      "                      <li>\n",
      "                       The\n",
      "                       <a href=\"http://www2.ljworld.com/\">\n",
      "                        Lawrence Journal-World\n",
      "                       </a>\n",
      "                       uses Beautiful Soup to\n",
      "                       <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "                        gather\n",
      "statewide election results\n",
      "                       </a>\n",
      "                       .\n",
      "                       <li>\n",
      "                        The\n",
      "                        <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "                         NOAA's Forecast\n",
      "Applications Branch\n",
      "                        </a>\n",
      "                        uses Beautiful Soup in\n",
      "                        <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "                         TopoGrabber\n",
      "                        </a>\n",
      "                        , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "                       </li>\n",
      "                      </li>\n",
      "                     </li>\n",
      "                    </li>\n",
      "                   </li>\n",
      "                  </li>\n",
      "                 </li>\n",
      "                </ul>\n",
      "                <p>\n",
      "                 If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "                 <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "                  the discussion\n",
      "group\n",
      "                 </a>\n",
      "                 .\n",
      "                 <h2>\n",
      "                  Development\n",
      "                 </h2>\n",
      "                 <p>\n",
      "                  Development happens at\n",
      "                  <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "                   Launchpad\n",
      "                  </a>\n",
      "                  . You can\n",
      "                  <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "                   get the source\n",
      "code\n",
      "                  </a>\n",
      "                  or\n",
      "                  <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "                   file\n",
      "bugs\n",
      "                  </a>\n",
      "                  .\n",
      "                  <hr/>\n",
      "                  <table>\n",
      "                   <tr>\n",
      "                    <td valign=\"top\">\n",
      "                     <p>\n",
      "                      This document is part of Crummy, the webspace of\n",
      "                      <a href=\"/self/\">\n",
      "                       Leonard Richardson\n",
      "                      </a>\n",
      "                      (\n",
      "                      <a href=\"/self/contact.html\">\n",
      "                       contact information\n",
      "                      </a>\n",
      "                      ). It was last modified on Wednesday, January 17 2024, 16:54:42 Nowhere Standard Time and last built on Monday, January 06 2025, 05:00:01 Nowhere Standard Time.\n",
      "                     </p>\n",
      "                     <p>\n",
      "                      <table class=\"licenseText\">\n",
      "                       <tr>\n",
      "                        <td>\n",
      "                         <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "                          <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "                         </a>\n",
      "                        </td>\n",
      "                        <td valign=\"top\">\n",
      "                         Crummy is © 1996-2025 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "                         <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "                          Creative Commons License\n",
      "                         </a>\n",
      "                         .\n",
      "                        </td>\n",
      "                       </tr>\n",
      "                      </table>\n",
      "                      <!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "                     </p>\n",
      "                    </td>\n",
      "                    <td valign=\"top\">\n",
      "                     <p>\n",
      "                      <b>\n",
      "                       Document tree:\n",
      "                      </b>\n",
      "                      <dl>\n",
      "                       <dd>\n",
      "                        <a href=\"http://www.crummy.com/\">\n",
      "                         http://www.crummy.com/\n",
      "                        </a>\n",
      "                        <dl>\n",
      "                         <dd>\n",
      "                          <a href=\"http://www.crummy.com/software/\">\n",
      "                           software/\n",
      "                          </a>\n",
      "                          <dl>\n",
      "                           <dd>\n",
      "                            <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "                             BeautifulSoup/\n",
      "                            </a>\n",
      "                           </dd>\n",
      "                          </dl>\n",
      "                         </dd>\n",
      "                        </dl>\n",
      "                       </dd>\n",
      "                      </dl>\n",
      "                      Site Search:\n",
      "                      <form action=\"/search/\" method=\"get\">\n",
      "                       <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "                      </form>\n",
      "                     </p>\n",
      "                    </td>\n",
      "                   </tr>\n",
      "                  </table>\n",
      "                 </p>\n",
      "                </p>\n",
      "               </p>\n",
      "              </p>\n",
      "             </p>\n",
      "            </p>\n",
      "           </p>\n",
      "          </p>\n",
      "         </p>\n",
      "        </p>\n",
      "       </p>\n",
      "      </p>\n",
      "     </p>\n",
      "    </p>\n",
      "   </p>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'https://www.crummy.com/software/BeautifulSoup/'\n",
    "r = requests.get(url)\n",
    "html_doc =  r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "\n",
      "\n",
      "Guido's Personal Home Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guido van Rossum - Personal Home Page\n",
      "\n",
      "\n",
      "\"Gawky and proud of it.\"\n",
      "Who I Am\n",
      "Read\n",
      "my \"King's\n",
      "Day Speech\" for some inspiration.\n",
      "\n",
      "I am the author of the Python\n",
      "programming language.  See also my resume\n",
      "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
      "pictures of me,\n",
      "my new blog, and\n",
      "my old\n",
      "blog on Artima.com.  I am\n",
      "@gvanrossum on Twitter.\n",
      "\n",
      "I am currently a Distinguished Engineer at Microsoft.\n",
      "I have worked for Dropbox, Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my resume.)  I created Python while at CWI.\n",
      "\n",
      "How to Reach Me\n",
      "You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but I receive too much email to respond\n",
      "to everything.\n",
      "\n",
      "Please understand that I do not give talks or keynotes any more,\n",
      "nor do I participate in podcasts or give interviews, etc.\n",
      "I am sorry, but I just receive too many such requests to decline\n",
      "them individually.\n",
      "Offering payment or trips to exotic locales just makes things worse, sorry.\n",
      "\n",
      "I also prefer not to receive questions about how to use Python\n",
      "(please read the documentation or search the internet for Python answers forums),\n",
      "bug reports (use the GitHub issue tracker),\n",
      "proposals for changes to the language (use Discourse),\n",
      "job offers (I'm happy where I am),\n",
      "or requests to join you in some far-fetched scheme to save humanity (though sometimes I like me a good rant :-).\n",
      "\n",
      "My Name\n",
      "My name often poses difficulties for Americans.\n",
      "\n",
      "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "sound clip.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "Spelling: my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "Alphabetization: in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "More Hyperlinks\n",
      "\n",
      "Here's a collection of essays relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "I own the official \n",
      "Python license.\n",
      "\n",
      "The Audio File Formats FAQ\n",
      "I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It was later maintained by Chris Bagwell, but seems to have been\n",
      "lost.  You can still find it on\n",
      "archive.org by searching for\n",
      "http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
      "SOX, to which I contributed\n",
      "some early code.\n",
      "\n",
      "\n",
      "\n",
      "\"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "pics.html\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "images/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "Resume.html\n",
      "https://docs.python.org\n",
      "https://github.com/python/cpython/issues\n",
      "https://discuss.python.org\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "https://web.archive.org/\n",
      "https://web.archive.org/web/20230627131911/http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
